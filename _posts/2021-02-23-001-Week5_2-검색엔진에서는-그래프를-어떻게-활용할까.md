---
title: Week5_2 검색엔진에서는 그래프를 어떻게 활용할까?
categories: [boostcamp]
tags: [부스트캠프, Graph]
math: true
comments: true
---

\- 이 강의정리본은 KAIST 신기정 교수님의 강의를 정리한 것임을 밝힙니다.\- 

### 페이지랭크의 배경

#### 웹과 그래프

- 웹 : 웹페이지 / 하이퍼링크로 구성된 방향성 있는 그래프.
  - 웹페이지 = node, 하이퍼링크 = edge에 해당함.
  - ![image-20210223094805116](/assets/img/post-images/image-20210223094805116.png)
  - 추가적으로, 웹페이지는 키워드 정보도 포함하고 있다.
- 현재는 수십억~수백억 개의 웹페이지가 존재함. 어떻게 우리가 원하는 웹페이지를 찾을 수 있는 것일까?

#### 구글 이전의 검색엔진

- 첫 번째 시도 : 웹을 거대한 디렉토리로 정리하는 것.
  - 옛날 YAHOO의 경우 : 예술, 뉴스, 건강, ... 등으로 정리하고자 함.
  - 그러나 이런 디렉토리 방법은 웹페이지가 증가함에 따라 카테고리 수와 깊이가 무한정 커지는 문제가 있다.
  - 또한 카테고리 분류가 모호한 웹페이지들도 많음.
- 두 번째 시도 : 웹페이지에 포함된 키워드에 의존한 검색 엔진
  - 입력한 키워드에 대해, 해당 키워드를 포함하는 웹페이지를 반환.
  - 그러나 이는 악의적인 웹페이지에 취약함.
    - 성인사이트에 `축구`라는 키워드를 보이지 않게 포함시키면, `축구`를 검색했을 때 해당 사이트가 나타날 수 있음.
- 그렇다면, 사용자 키워드와 관련성이 높고 신뢰할 수도 있는 웹페이지를 어떻게 찾을 수 있을까?
  - `Larry Page`, `Sergey Brin` : `The PageRank Citation Ranking`이라는 논문을 통해 이 질문에 답함.

### 페이지랭크의 정의

#### 투표관점

- 페이지랭크의 핵심 아이디어 : `투표`
  - 웹페이지는 하이퍼링크를 통해 투표를 함.
  - 위의 그림에서, `kaist.ac.kr`은 `ai.kaist.ac.kr`에 투표를 한다고 간주할 수 있음.
  - 웹페이지 `u`가 `v`로의 하이퍼링크를 포함한다면, `u`의 작성자가 판단하기에 `v`가 관련성이 높고 신뢰할 수 있음을 뜻함.
  - 즉, 들어오는 간선이 많을수록 신뢰할 수 있다는 뜻! 마치 인용횟수가 많은 논문이 신뢰할 수 있는 것처럼.
- 그러나, 이 역시도 악용될 소지는 있다.
  - 웹페이지를 여러 개 만들어 간선의 수를 부풀릴 수 있다.
  - SNS에서도 이는 흔히 발견된다. 예를 들어, 트위터에서 본인의 영향력을 과장하기 위하여 돈을 주고 일부러 간선의 수를 늘릴 수 있음.
- 이를 막으려면?
  - `가중 투표` : 신뢰할 수 있는 웹사이트의 투표를 더 중요하게 간주한다.
  - 일종의 `재귀` : 투표를 통해 측정하고자 하는 신뢰성과 관련성을, 다시 신뢰성을 통해 측정하려고 함. 즉, 출력을 입력처럼 사용함.
- 계산
  - 측정하려는 웹페이지의 관련성/신뢰도 = `페이지랭크 점수`
  - 각 웹페이지는 각각의 나가는 이웃에게 $$\frac{자신의\ 페이지랭크\ 점수}{나가는\ 이웃의\ 수}$$ 만큼의 가중치로 투표함.
  - ![image-20210223095859858](/assets/img/post-images/image-20210223095859858.png)
  - 위 예시에서 웹페이지 `j`는 `x, y, z`(나가는 이웃)에게 각각 $$\frac{r_j}{3}$$의 가중치로 투표를 한다.
  - $$r_j$$는 `j`의 페이지랭크 점수를 의미함.
  - $$r_j$$는 자신에게 들어오는 이웃이 투표한 가중치의 합으로 계산됨. 즉,  $$r_j=\frac{r_i}{3} + \frac{r_k}{4}$$
  - 이를 일반화시켰을 때의, 페이지 랭크의 점수는 아래와 같다.
  - ![image-20210223100114693](/assets/img/post-images/image-20210223100114693.png)
- 예시
  - ![image-20210223100847993](/assets/img/post-images/image-20210223100847993.png)
  - `y`는 스스로와, `a`에게 하이퍼링크를 걸고 있고, 또한 하이퍼링크가 들어오고 있다. 즉, 들어오는 이웃의 수도 `2`, 나가는 이웃의 수도 `2`이다.
  - `a`는 `y`와 `m`으로 나가고, 동시에 들어오고 있다.
  - `m`은 `a`에게만 나가고 들어오고 있다.
  - $$r_y = \frac{r_a}{2} + \frac{r_y}{2}$$
  - $$r_a = \frac{r_y}{2} + r_m$$
  - $$r_m = \frac{r_a}{2}$$
  - 즉, 3개의 변수에 대해 3개의 식이 있으므로, 연립방정식을 통해 페이지랭크 점수를 계산할 수 있다.

#### 임의보행 관점

- 페이지랭크를 임의 보행(Random Walk) 관점에서도 정의할 수 있다.

- 임의보행을 통해 웹을 서핑하는 웹서퍼를 가정하자.

  - 웹서퍼는 하이퍼링크 중 하나를 균일한 확률로 클릭하는 방식으로 웹서핑을 함.
  - 웹서퍼가 `t`번째 방문한 웹페이지가 웹페이지 `i`일 확률 = $$p_i(t)$$
  - $$p(t) = p_1(t) + p_2(t) + ... + p_n(t)$$, 즉 길이가 웹페이지 수와 같은 확률분포 벡터 
  - 그럼, `t+1`번째 방문한 웹페이지가 `j`일 확률은 어떻게 구할까?

  $$
  p_j(t+1) = \sum_{i\in N_{in}(j)}\frac{p_{i}(t)}{d_{out}(i)}
  $$

  - 즉, `j` 웹페이지로 들어오는 모든 `i` 웹페이지에 대해, `t`번째 방문한 웹페이지가 `i`일 확률을, `i`에서 나가는 이웃의 개수로 나눠준 값을 모두 더해주는 것!

- 웹서퍼가 위의 과정을 무한히 반복하고 나면, 즉 `t`가 무한히 커지면 확률분포 `p(t)`는 수렴하게 된다. 이는 다시 말해 $$ p(t) = p(t+1) = p$$ 가 성립하게 된다는 뜻이다.

- 그럼 위에서 계산한 수식을 아래와 같이 바꿀 수 있다.

$$
p_j = \sum_{i\in N_{in}(j)}\frac{p_{i}(t)}{d_{out}(i)}
$$

- 이 수식은, 투표 관점에서 정의한 페이지 랭크 점수 `r`과 같다. `r`을 `p`로 쓴 것 외에는 다른 게 없다.

### 페이지랭크의 계산

#### 페이지랭크 계산 : 반복곱

- 반복곱(Power Iteration) 

  - ① 각 웹페이지 `i`의 페이지랭크 점수 $$r_i^{(0)}$$(0번째 iteration의 r_i) 를 동일하게 $$\frac{1}{웹페이지의\ 수}$$로 초기화 한다.

  - ② 아래 식을 이용하여 각 웹페이지의 페이지랭크 점수를 갱신한다.

  - $$
    r_j^{(t+1)} = \sum_{i\in N_{in}(j)}\frac{r_{i}^{(t)}}{d_{out}(i)}
    $$

  - ③ 페이지랭크 점수가 수렴하였으면 종료한다. 아닌 경우 ②로 돌아간다.

  - ![image-20210223102834093](/assets/img/post-images/image-20210223102834093.png)

#### 문제점과 해결책

- 항상 반복곱이 수렴하는 것을 보장할 수 있는가?

  - `No`. 수렴하지 않고 계속 같은 pattern이 반복될 수도 있다. (진동)
  - ![image-20210223103016325](/assets/img/post-images/image-20210223103016325.png)
  - 이는 들어오는 간선은 있지만, 나가는 간선은 없는 정점 집합인 `Spider Trap`에 의한 문제라고 한다.

- 반복곱이 "합리적"인 점수로 수렴하는 것을 보장할 수 있는가?

  - `No`. "막다른 정점"에 의한 문제가 발생할 수 있다.
  - ![image-20210223103131280](/assets/img/post-images/image-20210223103131280.png)
  - 위 예시에서 페이지 랭크 점수는 모두 `0`으로 수렴하게 된다. 
  - 즉, 들어오는 간선은 있지만 나가는 간선은 없는 `막다른 정점(Dead End)`에 의한 문제.

- 위 문제들의 해결을 위해 `순간이동`(Teleport)이 도입됨.

  - 임의 보행 관점에서 웹서퍼의 행동을 아래와 같이 수정함.
  - ① 현재 웹페이지에 하이퍼링크가 `없`다면, 임의의 웹페이지로 순간이동
  - ② 현재 웹페이지에 하이퍼링크가 `있`다면, 앞면이 나올 확률이 `a`인 동전을 던짐.
    - ③ 앞면인 경우, 하이퍼링크 중 하나를 균일한 확률로 선택해 클릭함.
    - ④ 뒷면인 경우, 임의의 웹페이지로 순간이동함.
  - ①과 ④ 에서의 임의의 웹페이지란, 전체 웹페이지 중 하나를 의미함.

- 순간이동에 의해서 스파이더 트랩, 막다른 정점에 갇히는 문제가 해결된다.

- 또한, 동전을 던질 때의 앞면이 나올 확률 `a`를 감폭비율(Damping Factor)이라고 부르며 보통 `0.8`정도의 값을 사용함. 

- 순간이동의 도입에 의해, 페이지랭크 점수 계산식은 아래와 같이 바뀐다.

  - 즉, 막다른 정점에서 모든 다른 정점으로 가는 간선을 추가한다.

  - $$
    r_j = \sum_{i\in N_{in}(j)}(\alpha * \frac{r_{i}^{(t)}}{d_{out}(i)}) + (1-\alpha)\frac{1}{|V|}
    $$

  - `|V|` = 전체 웹페이지 수

  - 우항의 좌변은 하이퍼링크를 따라 정점 `j`에 도착할 확률

  - 우항의 우변은 순간이동을 통해 정점 `j`에 도착할 확률

![image-20210223104038584](/assets/img/post-images/image-20210223104038584.png)

- 위의 페이지랭크 점수 예시를 보자.
- `B`가 가장 큰 페이지랭크 점수를 갖고 있다. 당연한 것이, 많은 웹페이지들로부터 투표를 받고 있기 때문이다.
- 반면 아래의 보라색 웹페이지들은 나가는 간선만 있기 때문에 페이지랭크 값이 작다. 그럼에도 값이 있는 이유는, 순간이동을 통해 이들 정점에 도착할 확률이 있기 때문이다.
- `C`라는 정점은 간선을 `B`로부터만 받는데도 페이지랭크 점수가 높다. 이는 가장 점수가 높은 `B`로부터 `유일하게` 간선이 들어오기 때문이다.

### 실습 : 나무 위키 검색 엔진

#### 데이터 불러오기

#### 검색 1단계 : 부분그래프 구성

#### 검색 2단계 : 페이지랭크 점수 측정

