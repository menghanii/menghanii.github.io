---
title: KAIST 주재걸 교수님 Master Class(21/02/17)
categories: [boostcamp]
comments: true
---

#### 교수님께서 세부 연구분야를 선정하실 때 어떻게 결정하셨는지 스토리가 궁금합니다. P stage에서 nlp, vision 등 하위태스크를 결정해야하는데 이때 참고할 만한 팁이 있을까요?

- 요새 NLP의 핵심 : Pre-trained 모델. but resource가 부족한게 사실. 연구실 자원으로도 어려움.

- NLP쪽이 그만큼 하는 사람들이 비전 분야보다 훨씬 적다. 그러나 산업 현장이나 실제 니즈는 NLP쪽이 적지 않다. 그래서 본인도 자연어처리 쪽 사람을 찾는 문의가 더 많이오곤 한다. 비전은 발전도 빠르고, 하는만큼 성장할 수 있다. 그러나 그만큼 하는 사람도 많고 경쟁력도 높다.

- but NLP는 좋은 기회가 많이 주어질 수도 있다. 

- 결국 본인이 끌리는 분야 중 하나로 시작한 후, 여러 도메인/데이터에 대해 접근해봐라. 너무 깊이 고민하기보다는 부담없이 시작할 수 있는 쪽을 택하라.

#### 신입 AI 개발자에게 요구하는 역량은 어느 정도라고 생각하시나요?

- 학교에 있다보니까 , 산업 쪽 AI 개발자에게 요구하는 역량이 어떻게 되어야할지는 감이 없다.
- 딥러닝 쪽은 : MLP, CNN, RNN, Back-Propa의 기본 원리, loss function, ...
  - 최근에 나온 특정 기술을 발빠르게 적용할 수 있는 역량도 필요할 것 같다.
  - 영어 논문을 빠르게 읽고 이해할 수 있어야 하고, 관련 코드도 흡수할 수 있어야 한다.
- 많은 경우 회사(네이버, 기타 여러 메이저 회사 포함) 의 서류 심사, 코딩 테스트가 기본적으로 같이 수반되는 경우가 많은데, AI 관련한 모델 빌딩이나 성능을 올리는 코딩을 요구하지만, 많은 경우 알고리즘/자료구조 관련한 컴퓨터 사이언스쪽에서의 기초적인 지식도 요구되는 것 같다.
- 연구실에서 NLP를 열심히 하는 친구가 인턴 지원을 했는데, 어이없게 코테 1차 탈락하는 경우도 있었다.
- 따라서, 기초적인 부분들도 소홀히 하면 안된다.
- AI 자체에 대한 코딩 : tensorflow, pytorch + C에서의 포인터, 자료구조(linked-list, queue) 등 개발자에게 기초적/필수적으로 필요한 부분도 여력이 되면 해두는 게 좋지 않을까 함.
- 실제 산업계에서는 AI 앞 뒤로의 pipeline까지 서비스화 하는 전체 process -> AI 모듈은 이 중 빙산의 일각이다. 전체 서비스의 10~15% 정도밖에 안될 수도 있다. 따라서 앞뒤를 모두 잘 아는 것도 중요하다고 생각한다. Full-Stack 개발자!

#### 반어법, 돌려말하기 등 화용분석에까지 좋은 성능을 내는 모델은 못 본거 같은데, 이런 연구가 어떻게 진행되고 있는지?

- Sentiment Analysis에서도 반어법, 혹은 동일한 문장이지만 발화에 따라 전혀 다른 의미의 문장이 될 수 있는 경우가 존재함. - 많이들 연구하고 있음.
- 요새는, GPT-2, GPT-3, BERT 및 변종에 해당하는 다양한 모델들 -> 많은 데이터, 레이어 사이즈 많이 쌓고, resource 높이면 그냥 모든 nlp task가 잘 되는 현상에 대해 가치관의 혼란(?)이 생기고 있다. 
  - 모델을 좀 바꿔보고, 특정 문제에 특화된 모델을 만드는 아이디어 -> 최근 NLP 도메인에서 큰 효과를 보고 있지 못하다.
  - NLP를 정복하면 범용 인공지능(General AI)이 완성되는게 아닌가 .. 하는 생각도 들고 있다.
- 게리 마커스, 유시아 벤지오, 제프리 힌튼 등 어그로(?) 끄시는 분들 : "복잡다단한 추론을 다 딥러닝 레이어를 무지막지하게 쌓으면 해결된다." 라는 주장에 대한 논쟁이 일어나고 있음.
- 과연 이런 화용분석도 정복이 완전히 될지, 혹은 사람의 손이 들어가서 모델을 바꿔주어야 할지 좀 지켜봐야 하는 단계인 것 같다.

#### 많은 NLP 데이터를 구할 때 인터넷이 소스가 될 것 같은데, 크롤링이 많이 쓰이나요? 크롤링이 유효한 기술스택인지 궁금합니다.

- 네. 필요한 기술 스택이라고 봅니다. 
- 분명히 필요로 하는 기술이라고 봅니다. 연구실에서도 실제로 크롤링을 많이 하고 있음.
- 크롤링 자체에서 어려움을 겪거나 하는 것 같진 않다. 이질적인 형태의 코딩(reverse engineering)의 느낌은 있지만 어려운 것 같지는 않다.

#### AI를 공부하다 보면, 직관적으로 와닿지 않아 답답한 느낌이 있습니다. 어떻게 받아들이고 넘어가시나요? 

- 원동력 : 전반적으로 협업의 중요성이 대두되고 있다. 혼자서만 꾸준히 하는것보다, 여러 사람들이 같이 일을 해서 하나의 task를 빠르게 해결하는 측면이 있다. 그런 측면에서, 공부를 지속할 때도 혼자 공부를 하는데는 한계가 있다고 생각함. 
- 어떤 형태로든 마음 맞는 사람들과 공부해보는 것을 고려해보자. 본인의 식견을 넓히는데 도움을 주는 사람들을 가까이 하라.
- 똑같은 걸 봐도 어떤 사람은 1만큼 보고, 어떤 사람은 10개를 보는 경우도 있다.
  - 성공적인 모델이 만들어진 배경에는 여러가지 시도, 왜 안될까에 대한 원인을 끊임없이 분석/고민이 있다.

- 외부적으로 내세울만한 실적이 없으면, 기초가 아무리 탄탄해도 평가자가 이를 느낄 수 있는 포인트가 없을 수 있다. 
  - CV 100개씩 들어오는데 시간도 없는데 실적 위주로 볼 것이다.

#### 박사 유학에 대한 교수님의 생각

- 해외 박사는 굉장히 좋은 기회라고 생각한다.
- 다만 머신러닝, 인공지능 분야의 연구로 보면 전세계적으로 연구적/기술적 측면에서 상향평준화되고 있다는 생각은 든다. 
- 예전에는 미국 stanford, 카네기멜론 등 CS의 top school에서의 연구는 딱 거기서만 할 수 있었다고 한다면, 요즘은 중국/유럽/한국 등에 훌륭한 교수님도 많이 계시고, 연구나 실력에 있어서는 상향평준화되어 있다고 본다. 즉, 우리나라도 좋아졌다고 생각이 든다.
- 그러나 미국에 취업하고자 한다면 교두보로서 미국 석/박은 좋다고 생각한다.

#### Top-down 방식의 접근 방식이 좋을지, 기초 개념을 섭렵하면서 올라가는게 좋을지?

- 답이 없는 것 같습니다... 저도 항상 고민을 하고 있구요.
- 선택과 집중, 밸런스를 어느 정도 두느냐의 문제인 것 같다.
- 최신논문만 봐도 한계가 있고, 기초 공부만 해도 고통스러움.
  - 기초 공부는 이게 어떻게 쓰이는지 알 수 없다는 문제도 있음.
- 적절한 비율을...찾아라...
- **로드맵** 같은 건 본인이 사전에 설계/계획하는게 좋을 것 같다.
  - 교수님의 경우, 최적화 이론은 아예 모른다. 기본적인 건 알지만..
  - convex, duality, 라그랑지안 등에 전문이 아님.
- Big Picture : 내가 무엇이 필요한지를 사전에 잘 인지하고 계획을 세우는 게 좋다. 방향성을 갖고 있는게 좋지 않을까.

#### 해외 온라인 석사는 어떻게 생각하시나요?

- 내실이 좀 없어 보인다. 아무도 날 케어해주지 않는다는 피드백을 많이 받음.
- 요즘은 좋은 강의들이 지천에 널려있고, 공짜로 들을 수 있다..

#### 프론트엔드와 AI의 결합은 어떤게 존재할까요? 

- 교수님도 사용자와의 접점을 흥미롭게 생각하고 연구도 그쪽으로 하고자 하심.
- 개인적으로는 굉장히 유망한 분야라고 생각함. 프론트엔드라는 것은 개발쪽 effort가 굉장히 헤비함. 버튼 하나를 만들어도 빡셈. 엄청 피곤 + 어렵고 + 번거로울 수 있다. 
- AI 기술은 그 자체에만 집중하고 있고, 프론트까지 접점이 있지는 않다.
- 그러나 서비스화가 된다든지에 있어서는 필수적인 요소라고 생각함. 필요한데 조금 간과되고 있는 부분이 아닌가 생각됨.
- Human-Computer Interaction 분야 : AI와 접목하고자 하는 다양한 시도가 있음. CHI(카이)라는 학회가 가장 좋고, data visualization 쪽으로도 접목이 많이 된다. 그쪽 논문을 찾아보는 것도 좋다. 

#### 퍼포먼스 향상을 위해 C++을 사용하는 것이 성능 향상을 얻을 수 있나요?

- 그렇습니다.
- 일례로, `python`도 그렇고, `pytorch`, `tensorflow` 등의 메모리 단에서 우리는 모르는 채로 코딩을 하지 않습니까? 
  - 그게 C 등으로 잘 만들어져 있어서 그렇다...

- BUT 여기까지 공부하는 데엔 한계가 있다. 전체적으로 Big Picture를 가지고 있어야한다. 방향성을 어디로 잡을지. High-Level(Pruning, distilation) 을 할지, Low-Level을 주목할지.

#### 성공적인 논문을 쓰고 졸업하기 위해 알려주실 수 있는 연구 팁?

- 주변 동료! 협업! 

#### 랩실 학생 선발 기준?

- 딱히 일관된 선발 기준이 있지는 않다.
- 기초적인 내용들을 깊이 알고 있고, ... FAQ가 웹사이트에 있으니 참고!

#### LSTM , GRU의 패러다임이 Transformer 이후 바뀌었는데, 이들의 실용적 유통기한?

- 적지 않은 시간을 할애해서 강의에 포함을 햇는데,
- 실제 최근은 Transformer로 대체되는 상황. 
- 그렇다고 LSTM, GRU가 아예 사장된 기술이라고 판단하기에는 섣부르지않을까 하는 생각이 든다.
  - 가령 구글에서 medical data를 가지고 연구하는 지인들의 얘기를 들어보면, 다양한 sequence data, time series data에서는 LSTM, GRU가 성능이 잘나오는 경우도 많다고 들었음.
- 따라서, 꾸준히 쓰이는 곳은 아직 많지 않을까
- Long Term Dependency를 근본적으로 해결한게 Transformer인데,
  - short term 등을 예측하는 것은 LSTM 계열이 더 좋은 경우도 있다.
  - 주식 가격 -> 단기적 추세를 예측해야할 수도 있다. 

#### 모델의 구조를 이해하기 위해서 항상 간단한 예시를 들어주시면 정말 이해가 잘 되었는데요. 혼자 모델을 공부할 때 간단한 예시를 통해 이해하고자 하는 방법이 좋은 방법이라고 생각하시나요? 혹은 선형대수/통계와 등을 더 깊이있게 공부한 후 모델의 수학적 구조를 이해하는게 좋을까요? 

- 교수님 같은 경우는 머리가 안좋아서(?) 아주 쉬운 예제를 들어 이야기를 안해주면 어렵다.
- Bayesian, ... 엄청 어려운 수학적 모델에서 답답함을 많이 느꼈음.
- 제가 남들에게 설명해줄 때도 한 마디로 명쾌하게 설명해줄 수 없으면 제대로 아는게 아니다.
- 수학적으로 복잡하거나 어려운 걸 만났을 때, simple 한 예 (learning example)를 만들어가지고 공부를 하려고하는 편. 오래걸리는 문제는 있다..
- 주변에 잘 토의/논의할 수 있는 , 혹은 가르쳐 줄 수 있는 선배/동료들이 있는게 좋을 것 같다.

